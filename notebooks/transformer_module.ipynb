{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self attention\n",
    "sequence $x$ is $b x t x k$. batch sequence length and dimension\n",
    "Follwoing we add linear transformations in order to provide learnable parameters.\n",
    "* $W_q$ transform $x_i$ to $q_i$ query vector. Compared to every other vector inorder to establish weights for its own output $y_i$\n",
    "* $W_k$ transform $x_i$ to $k_i$ key vector. Used for $x_i$ being compared to the queries, to establish the weights for other $y_j$\n",
    "* $W_v$ transform $x_i$ to $v_i$ vector to be weighted and that actually encodes the information.\n",
    "\n",
    "<img src=\"images/learnable-weights.png\"  width=\"500\" height=\"600\">\n",
    "\n",
    "Hence, the self attention layer for each $y_i$ will be the following\n",
    "\n",
    "\n",
    "<img src=\"images/learnable-structure.png\"  width=\"500\" height=\"600\">\n",
    "\n",
    "Small tricks:\n",
    "\n",
    "* Divide by $\\sqrt{k}$ to reduce input values of the softmax (as dimension increases it reduces by the euclidean lenght, read bibliography for more explanations)\n",
    "* Multi-head attention: learn many query, keys values for each input (paralllel self attention) and concatenate at the end. Allows to focus and learn different queries for each input. Each $W_q^r$, $W_k^r$ and $W_v^r$ is an attention head.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, k, heads=10):\n",
    "        super().__init__()\n",
    "        #Compute Linear Transformations\n",
    "        self.transform_queries = nn.Linear(k, k*heads, bias=False)\n",
    "        self.transform_keys = nn.Linear(k, k*heads, bias=False)\n",
    "        self.transform_values = nn.Linear(k, k*heads, bias=False)\n",
    "        # Linear Transform that reduces dimensionality\n",
    "        self.dimension_reduce = nn.Linear(k*heads, k, bias=False)\n",
    "        self.k = k\n",
    "        self.h = heads\n",
    "        \n",
    "    def forward(self,x): #input b x t x k\n",
    "        b, t, k = x.size()\n",
    "        h = self.h\n",
    "        \n",
    "        #Transform: b,t,k => b,t,k*h \n",
    "        queries = self.transform_queries(x)\n",
    "        keys = self.transform_keys(x)\n",
    "        values = self.transform_values(x)\n",
    "        #Separate heads from dimension\n",
    "        # b,t,k*h => b,t,h,k\n",
    "        queries = queries.view(b,t,h,k)\n",
    "        keys = keys.view(b,t,h,k)\n",
    "        values = values.view(b,t,h,k)\n",
    "        #Matrix multiplication for each batch and each head. Hence we merge heads and batch in order tu use torch.bmm\n",
    "        # Transpose b,t,h,k => b,h,t,k\n",
    "        # Merge dim b,h,t,k => b*h,t,k\n",
    "        queries = queries.transpose(1,2).contiguous().view(b*h,t,k)\n",
    "        keys = keys.transpose(1,2).contiguous().view(b*h,t,k)\n",
    "        values = values.transpose(1,2).contiguous().view(b*h,t,k)\n",
    "        # Scale\n",
    "        queries = queries /(k**(0.25))\n",
    "        keys = keys/(k**(0.25))\n",
    "        \n",
    "        #Use torch batch matrix mult, performs a matrix mult for each elemt of the batch.\n",
    "        #Batch consist of batch sample and head\n",
    "        # b*h,t,k x b*h,k,t => b*h,t,t \n",
    "        weights = torch.bmm(queries,keys.transpose(1,2))\n",
    "        soft_weights = F.softmax(weights, dim=2)\n",
    "        #Multiply weights b*h,t,t x b*h,t,k => b*h,t,k \n",
    "        #(each row weight contains weights for each row vectors, row weights linear combination of rowvectors) \n",
    "        output = torch.bmm(soft_weights, values).view(b, h, t, k)\n",
    "        #Merge the h heads on the k dimension\n",
    "        #Transpose b,h,t,k =>  b,t,h,k \n",
    "        #View(merge) b,t,h,k => b,t,h*k \n",
    "        output = output.transpose(1,2).contiguous().view(b,t,h*k)\n",
    "        #Reduce dimension b,t,h*k => b,t,k\n",
    "        return self.dimension_reduce(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0158, -0.1386, -0.0345, -0.2060, -0.1662, -0.0297, -0.0587,\n",
       "            0.0035,  0.0146,  0.0096],\n",
       "          [-0.0151, -0.1365, -0.0336, -0.2070, -0.1653, -0.0281, -0.0588,\n",
       "            0.0049,  0.0124,  0.0078],\n",
       "          [-0.0152, -0.1378, -0.0355, -0.2058, -0.1654, -0.0293, -0.0593,\n",
       "            0.0035,  0.0136,  0.0091],\n",
       "          [-0.0155, -0.1352, -0.0342, -0.2078, -0.1673, -0.0283, -0.0595,\n",
       "            0.0043,  0.0115,  0.0077],\n",
       "          [-0.0163, -0.1348, -0.0337, -0.2076, -0.1673, -0.0286, -0.0591,\n",
       "            0.0064,  0.0126,  0.0060]],\n",
       " \n",
       "         [[-0.0696, -0.1451, -0.0073, -0.2360, -0.0398, -0.0289,  0.0026,\n",
       "           -0.0469,  0.0683, -0.0650],\n",
       "          [-0.0713, -0.1461, -0.0069, -0.2358, -0.0411, -0.0280,  0.0022,\n",
       "           -0.0500,  0.0693, -0.0634],\n",
       "          [-0.0695, -0.1478, -0.0072, -0.2371, -0.0425, -0.0255,  0.0025,\n",
       "           -0.0532,  0.0684, -0.0637],\n",
       "          [-0.0699, -0.1484, -0.0040, -0.2378, -0.0415, -0.0244,  0.0030,\n",
       "           -0.0544,  0.0683, -0.0622],\n",
       "          [-0.0696, -0.1473, -0.0039, -0.2406, -0.0402, -0.0258,  0.0036,\n",
       "           -0.0521,  0.0675, -0.0647]],\n",
       " \n",
       "         [[-0.0132, -0.0768, -0.0413, -0.2357, -0.1417, -0.0888, -0.0220,\n",
       "            0.0400,  0.0091, -0.0664],\n",
       "          [-0.0127, -0.0776, -0.0379, -0.2374, -0.1403, -0.0895, -0.0240,\n",
       "            0.0430,  0.0082, -0.0663],\n",
       "          [-0.0145, -0.0735, -0.0358, -0.2338, -0.1401, -0.0913, -0.0241,\n",
       "            0.0410,  0.0091, -0.0606],\n",
       "          [-0.0126, -0.0756, -0.0376, -0.2361, -0.1410, -0.0897, -0.0234,\n",
       "            0.0394,  0.0090, -0.0647],\n",
       "          [-0.0129, -0.0766, -0.0387, -0.2355, -0.1400, -0.0901, -0.0229,\n",
       "            0.0412,  0.0086, -0.0645]],\n",
       " \n",
       "         [[-0.0566, -0.1387,  0.0853, -0.2812, -0.1056, -0.0858, -0.1365,\n",
       "           -0.0199, -0.0398, -0.0023],\n",
       "          [-0.0549, -0.1409,  0.0876, -0.2794, -0.1051, -0.0875, -0.1404,\n",
       "           -0.0222, -0.0396, -0.0029],\n",
       "          [-0.0577, -0.1404,  0.0887, -0.2814, -0.1062, -0.0874, -0.1389,\n",
       "           -0.0207, -0.0389, -0.0030],\n",
       "          [-0.0571, -0.1388,  0.0866, -0.2804, -0.1066, -0.0877, -0.1385,\n",
       "           -0.0186, -0.0398, -0.0017],\n",
       "          [-0.0575, -0.1389,  0.0871, -0.2846, -0.1069, -0.0883, -0.1395,\n",
       "           -0.0169, -0.0393, -0.0026]],\n",
       " \n",
       "         [[-0.1378, -0.1640,  0.1073, -0.2934, -0.0598,  0.0444, -0.0437,\n",
       "            0.0494,  0.0527,  0.0603],\n",
       "          [-0.1375, -0.1638,  0.1064, -0.2952, -0.0598,  0.0462, -0.0426,\n",
       "            0.0481,  0.0559,  0.0583],\n",
       "          [-0.1364, -0.1646,  0.1066, -0.2952, -0.0591,  0.0445, -0.0440,\n",
       "            0.0461,  0.0550,  0.0577],\n",
       "          [-0.1381, -0.1640,  0.1078, -0.2947, -0.0595,  0.0445, -0.0429,\n",
       "            0.0481,  0.0544,  0.0599],\n",
       "          [-0.1372, -0.1644,  0.1065, -0.2939, -0.0601,  0.0456, -0.0424,\n",
       "            0.0489,  0.0545,  0.0604]],\n",
       " \n",
       "         [[-0.0691, -0.1427, -0.0049, -0.1649, -0.1161, -0.0564, -0.0691,\n",
       "           -0.0173,  0.0589,  0.0399],\n",
       "          [-0.0679, -0.1427, -0.0037, -0.1640, -0.1139, -0.0569, -0.0714,\n",
       "           -0.0191,  0.0553,  0.0356],\n",
       "          [-0.0680, -0.1394,  0.0007, -0.1640, -0.1132, -0.0579, -0.0687,\n",
       "           -0.0175,  0.0578,  0.0328],\n",
       "          [-0.0696, -0.1446,  0.0004, -0.1648, -0.1159, -0.0534, -0.0660,\n",
       "           -0.0196,  0.0609,  0.0352],\n",
       "          [-0.0703, -0.1439, -0.0012, -0.1644, -0.1158, -0.0560, -0.0664,\n",
       "           -0.0192,  0.0600,  0.0358]],\n",
       " \n",
       "         [[-0.0195, -0.0804,  0.0473, -0.2569, -0.1962, -0.0850, -0.1523,\n",
       "            0.0194, -0.0456,  0.0133],\n",
       "          [-0.0195, -0.0817,  0.0507, -0.2582, -0.1968, -0.0850, -0.1553,\n",
       "            0.0205, -0.0474,  0.0155],\n",
       "          [-0.0201, -0.0810,  0.0518, -0.2581, -0.1965, -0.0846, -0.1535,\n",
       "            0.0211, -0.0480,  0.0140],\n",
       "          [-0.0186, -0.0819,  0.0505, -0.2586, -0.1969, -0.0848, -0.1553,\n",
       "            0.0205, -0.0489,  0.0157],\n",
       "          [-0.0200, -0.0804,  0.0511, -0.2578, -0.1953, -0.0858, -0.1542,\n",
       "            0.0179, -0.0463,  0.0150]],\n",
       " \n",
       "         [[-0.0604, -0.1393,  0.0478, -0.2861, -0.0407, -0.1236, -0.0622,\n",
       "            0.0249,  0.0326,  0.0101],\n",
       "          [-0.0609, -0.1388,  0.0490, -0.2865, -0.0411, -0.1239, -0.0631,\n",
       "            0.0265,  0.0328,  0.0091],\n",
       "          [-0.0620, -0.1372,  0.0481, -0.2869, -0.0429, -0.1233, -0.0627,\n",
       "            0.0261,  0.0334,  0.0098],\n",
       "          [-0.0607, -0.1402,  0.0495, -0.2859, -0.0407, -0.1241, -0.0645,\n",
       "            0.0244,  0.0324,  0.0107],\n",
       "          [-0.0605, -0.1388,  0.0477, -0.2847, -0.0425, -0.1244, -0.0663,\n",
       "            0.0224,  0.0331,  0.0121]]], grad_fn=<UnsafeViewBackward>),\n",
       " torch.Size([8, 5, 10]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fast check\n",
    "self_attention = SelfAttention(k=10,heads=20)\n",
    "sample_input = torch.rand(8,5,10)\n",
    "output = self_attention(sample_input)\n",
    "output, output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers\n",
    "\n",
    "\"Any architecture designed to process a connected set of unitsâ€”such where the only interaction between units is through self-attention\"\n",
    "<img src=\"images/transformers.png\"  width=\"500\" height=\"600\">\n",
    "\n",
    "It is to say seq-to-seq all at once\n",
    "\n",
    "Basic structure:\n",
    "* Self attention\n",
    "* Norm layer\n",
    "* FeedForward Net\n",
    "* Norm Layer\n",
    "\n",
    "Additionaly residual blocks and keypoint is to combine feedforward with self attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
